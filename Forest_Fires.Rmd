---
title: "DSC5103 Final Project: Forest Fires"
subtitle: 'Prediction of Burn Area using Meteorological Data'
author: "Section A1 Group 10"
date: "Oct 2018"
output:
  html_document:
    highlight: tango
    theme: yeti
---
<!--
comments must be put in an HTML comment form
-->

```{r set-options, echo=FALSE, cache=FALSE}
options(width = 100)  # set output width, turn off scientific notation for big numbers
# knitr::opts_chunk$set(echo = TRUE) # include=FALSE
```

## Introduction
In this project, we will be studying the Forest Fires Data Set(source/cite). This dataset covers meteorological data for forest fires in Portugal from 2008, with 13 attributes each for 517 data points. 

### Data Sources

1. https://archive.ics.uci.edu/ml/datasets/forest+fires

### Problem 

We will be studying the following problem(s):

* Predict the burned area of a forest fire, given the prevailing meteorological conditions.
    + This data can be obtained in real-time, and is non-costly, and this prediction can provide instant feedback to the appropriate diaster response teams.
    + Could be possibly be imbalanced problem, if converted to multi-class classification.


### Evaluation Metrics

Need to do some work on which one would be appropriate based on problem outlined above.

* Regression - RMSE, MAD
* Classification - recall, overall accuracy, AUC/ROC
* Bingo Classification Accuracy?
* 1-Away Classification Accuracy? 

## Motivation
With forest fires sweeping Southern California, leaving much destruction in their wake, there is need for a tool such as ours to improve firefighting resource management and disaster response. Spin some more stuff on why this work is important, and why we chose it/use case - what Xs you will get in the future to predict this Y.

## Literature Review
While topical, this data set hasn't been studied extensively. However, the frame of reference for our regression task is work by * P. Cortez and A. Morais (2007)*.

Kaggle/GitHub sources:

1. https://www.kaggle.com/elikplim/predict-the-burned-area-of-forest-fires
2. 

## Exploratory Data Analysis
We did some initial EDA and visualization to get an idea of our next steps: the required data pre-processing and balancing, and some hints on possible feature engineering. 

### Schema
```{r eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}

library(tidyverse)
library(psych)
library(caretEnsemble)
library(caret)
library(corrplot)
library(ModelMetrics)

# load data
data <- read.csv(file = "data/forestfires.csv", stringsAsFactors = T)

summary(data)
str(data)
head(data)
```


### Distribution of Target Class
```{r eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}
ggplot(data,aes(data$area)) + geom_histogram()

```

### EDA
```{r eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}
# describe(data)

#columns
names(data)
#numeric data
names(Filter(is.numeric,data))
#factor data
names(Filter(is.factor,data))

#check NAs
sum(is.na(data))

# check correlation - there are some colinearity based on which we might drop features
corPlot(Filter(is.numeric,data))

# visualize relation between target and major predictors
pairs(dplyr::select(data,c('rain', 'wind', 'temp', 'RH', 'area', 'DC', 'ISI', 'FFMC')))

# day/month wise incidents
plot(data$day, col='purple')
plot(data$month, col='purple')
# there are more incidents on weekends (fri/sat/sun), it might mean that campers vactioning might have caused/spotted fires


#Day/Month wise area Burnt 
ggplot(data, aes(x=data$month,data$area)) + geom_boxplot(outlier.shape=NA) + 
  geom_jitter(col='red') + theme_bw()

ggplot(data, aes(x=data$day,data$area)) + geom_boxplot(outlier.shape=NA) + 
  geom_jitter(col='red') + theme_bw()
```

## Data Preparation

### Train-Validation Split
Next, we will prepare the training and test dataset, as well as the 10 CV folds, for later model comparison.
```{r eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}
# split training and test data 70/30
N <- nrow(data)
set.seed(1)
train.index <- sample(1:N, round(N*0.7))
test.index <- -train.index

# create a normalized copy of data
normalize_c = function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

denormalize <- function(x, min_x, max_x) {
  return(x * (max_x - min_x) + min_x) 
}

data_norm = data %>% mutate_at(names(Filter(is.numeric,data)),normalize_c)
```

Let's separate the test data for GBM use.
```{r eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}


```


## Feature Engineering/Creation
```{r eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}

```

## Modelling

1. Elastic Net
```{r glmnet, eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}
library(glmnetUtils)
library(MASS)
library(boot)

model_lm = glm(area~ rain+wind+temp+RH+DC+ISI+FFMC+month+day,
               data=data_norm[train.index,], family = 'gaussian')
summary(model_lm)
glm.diag.plots(model_lm)
#cook's statistics shows that few outliers are heavily affecting prediction
#As shown in the histogram of area, there many values at 0 but few cases with very high area burnt such as 900-1100 hectors. we can't remove these outliers as these are the cases which we are trying to predicts 
#Residuals plot shows a very flat points instead of a uniform distribution again because of extreme outlier influence

#this means linear regression models will not be good for this case

train_pred_area_lm = as.numeric(denormalize(model_lm$fitted.values,min(data$area), max(data$area)))

sqrt(mean((data[train.index,'area']-train_pred_area_lm)^2))

model_step = stepAIC(model_lm, direction = 'both')
model_step$anova

train_pred_area_step = as.numeric(denormalize(model_step$fitted.values,min(data$area), max(data$area)))

sqrt(mean((data[train.index,'area']-train_pred_area_step)^2))

model_lasso = cv.glmnet(area~.,
               data=data_norm[train.index,], nfolds=10, use.model.frame = T, alpha = 1)

lam_lasso = model_lasso$lambda.min

train_pred_area_lasso = as.numeric(denormalize(predict(model_lasso, s=lam_lasso, data_norm[train.index,], exact=TRUE),min(data$area),max(data$area)))

sqrt(mean((data[train.index,'area']-train_pred_area_lasso)^2))

model_ridge = cv.glmnet(area~rain+wind+temp+RH+DC+ISI+FFMC+month+day,
               data=data_norm[train.index,], nfolds=10, use.model.frame = T, alpha = 0)

lam_ridge = model_ridge$lambda.min

train_pred_area_ridge = as.numeric(denormalize(predict(model_ridge, s=lam_ridge, data_norm[train.index,], exact=TRUE),min(data$area),max(data$area)))

sqrt(mean((data[train.index,'area']-train_pred_area_ridge)^2))

# my intial suspicion is proved that linear models are unfit for this case. 
```

2. k-Nearest Neighbours Regression
```{r}
library(onehot)
library(class)
library(caret)
library(FNN)
library(Metrics)

#encode factors for KNN
data_norm$month = as.factor(data_norm$month)
data_norm$day = as.factor(data_norm$day)

encoder = onehot(data_norm, max_levels = 100)
knn_data = as.data.frame(predict(encoder, data_norm))

#separate train and test for KNN
train_knn = knn_data[train.index,]
test_knn = knn_data[-train.index,]

#Optimal K
ks = 1:30
mse.train = numeric(length=length(ks))
mse.test  = numeric(length=length(ks))

for (i in seq(along=ks)) {
  model.train = knn.reg(train_knn, train_knn, train_knn$area, k=ks[i])
  model.test  = knn.reg(train_knn, test_knn, train_knn$area, k=ks[i])
  mse.train[i] = mean((train_knn$area - model.train$pred)^2)
  mse.test[i] = mean((test_knn$area - model.test$pred)^2)
}

k.opt = ks[which.min(mse.test)]

#training KNN regression

knn_pred = knn.reg(train_knn, test_knn, train_knn$area, k=k.opt)
knn_rmse = rmse(test_knn$area, as.numeric(denormalize(knn_pred$pred,min(data$area), max(data$area))))
knn_rmse # 15.3
```


3. Support Vector Machines
```{r}
#### Support Vector Machines 

library(e1071)

train_data = data_norm[train.index,]
test_data = data_norm[-train.index,]

#linear kernel
svm_linear = svm(area ~ rain + wind + temp + RH + DC + ISI + FFMC, data=train_data, kernel = 'linear', cost = 1)
pred.linear = predict(svm_linear, test_data)
pred.linear.denormalized = as.numeric(denormalize(pred.linear,min(data$area), max(data$area)))
svm_lin_rmse = rmse(test_data$area, pred.linear.denormalized)
svm_lin_rmse # 7.4

tune_linear = tune(svm, area ~ rain + wind + temp + RH + DC + ISI + FFMC,  data = train_data, kernel='linear',
                       ranges = list(epsilon = seq(0,1,0.1), cost = 2^(2:6)))
tuned_linear = tune_linear$best.model
tuned_linear_pred = predict(tuned_linear, test_data) 
tuned.pred.linear.denormalized = as.numeric(denormalize(tuned_linear_pred,min(data$area), max(data$area)))
svm_lin_tuned_rmse = rmse(test_data$area, tuned.pred.linear.denormalized)
svm_lin_tuned_rmse # 14.8

#polynomial kernel
svm_poly = svm(area ~ rain + wind + temp + RH + DC + ISI + FFMC, data=train_data, kernel = 'polynomial', cost = 1)
pred.poly = predict(svm_poly, test_data)
pred.poly.denormalized = as.numeric(denormalize(pred.poly,min(data$area), max(data$area)))
svm_poly_rmse = rmse(test_data$area, pred.poly.denormalized)
svm_poly_rmse # 33.1

tune_poly = tune(svm, area ~ rain + wind + temp + RH + DC + ISI + FFMC,  data = train_data, kernel='polynomial',
                   ranges = list(epsilon = seq(0,1,0.1), cost = 2^(2:6)))
tuned_poly = tune_poly$best.model
tuned_poly_pred = predict(tuned_poly, test_data) 
tuned.pred.poly.denormalized = as.numeric(denormalize(tuned_poly_pred,min(data$area), max(data$area)))
svm_poly_tuned_rmse = rmse(test_data$area, tuned.pred.poly.denormalized)
svm_poly_tuned_rmse # 30.8

#RBF kernel
svm_rbf = svm(area ~ rain + wind + temp + RH + DC + ISI + FFMC, data=train_data, kernel = 'radial', cost = 1)
pred.rbf = predict(svm_rbf, test_data)
pred.rbf.denormalized = as.numeric(denormalize(pred.rbf,min(data$area), max(data$area)))
svm_rbf_rmse = rmse(test_data$area, pred.rbf.denormalized)
svm_rbf_rmse # 7.6

tune_rbf = tune(svm, area ~ rain + wind + temp + RH + DC + ISI + FFMC,  data = train_data, kernel='radial',
                 ranges = list(epsilon = seq(0,1,0.1), cost = 2^(2:8)))
tuned_rbf = tune_rbf$best.model
tuned_rbf_pred = predict(tuned_rbf, test_data) 
tuned.pred.rbf.denormalized = as.numeric(denormalize(tuned_rbf_pred,min(data$area), max(data$area)))
svm_rbf_tuned_rmse = rmse(test_data$area, tuned.pred.rbf.denormalized)
svm_rbf_tuned_rmse # 17.5

#Sigmoid kernel
svm_sigmoid = svm(area ~ rain + wind + temp + RH + DC + ISI + FFMC, data=train_data, kernel = 'sigmoid', cost = 1)
pred.sigmoid = predict(svm_sigmoid, test_data)
pred.sigmoid.denormalized = as.numeric(denormalize(pred.sigmoid,min(data$area), max(data$area)))
svm_sigmoid_rmse = rmse(test_data$area, pred.sigmoid.denormalized)
svm_sigmoid_rmse 

tune_sigmoid = tune(svm, area ~ rain + wind + temp + RH + DC + ISI + FFMC,  data = train_data, kernel='sigmoid',
                ranges = list(epsilon = seq(0,1,0.1), cost = 2^(2:8)))
tuned_sigmoid = tune_sigmoid$best.model
tuned_sigmoid_pred = predict(tuned_sigmoid, test_data) 
tuned.pred.sigmoid.denormalized = as.numeric(denormalize(tuned_sigmoid_pred,min(data$area), max(data$area)))
svm_sigmoid_tuned_rmse = rmse(test_data$area, tuned.pred.sigmoid.denormalized)
svm_sigmoid_tuned_rmse 

```


4. Random Forest
```{r randomforest, eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}
library("randomForest")

# tune random forest (mtry) manually
mse.rfs <- rep(0, 12) # repeat '0' 12 times

for(m in 1:12){
    set.seed(12345)
    rf <- randomForest(area ~ ., data = data, subset = train.index, ntree=501, mtry=m)
    mse.rfs[m] <- rf$mse[501]
}

plot(1:12, mse.rfs, type = "b", xlab="mtry", ylab="OOB Error")

# fit a random forest model
set.seed(12345)
model.rf <- randomForest(area ~ ., data = data, subset=train.index, ntree=501, mtry=1)
plot(model.rf)

# predict
pred.rf <- predict(model.rf, newdata=data[test.index,]) 

# rmse in test data
rmse(pred.rf, data[test.index,"area"]) # ~29.21
```

5. XGBoost
```{r xgboost, eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}
# x.test <- heart[test.index, 1:13]
# y.test <- heart[test.index, 14]
```

6. Ensemble 
```{r ensemble, eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}

area_corr <- cor(dplyr::select(data, -c("month","day")))
corrplot(area_corr, method = "circle")

set.seed(17)

train.index <- createDataPartition(data$area, p = .8, list = FALSE)
ensemble_train <- data[train.index,]
ensemble_test <- data[-train.index,]

folds <- createFolds(ensemble_train$area,5)

control <- trainControl(method='repeatedcv', number=5, repeats=2, index=folds, search = 'grid', savePredictions = 'final')

algos <- c('xgbTree','knn')

models <- caretList(area~., data=ensemble_train, metric = 'RMSE', trControl=control, methodList=algos)

models_perf <- resamples(models)
modelCor(models_perf)

stack_control <- trainControl(method = 'repeatedCV', number = 2, repeats = 5)

stack_lm <- caretStack(models, method='lm',  trControl=stack_control)

pred_stack <- predict(stack_lm, ensemble_test)

## Accuracy and RMSE of Stacking Model
stack_accuracy <- RMSE(pred_stack, ensemble_test$area)
stack_accuracy
```

## Results and Model Comparison
* Relevant plots, tables, discussions

## Insights
* Variable importance plots, other interpretations.

## Conclusion
* Limitations, scope for improvement
* Multi-class classification by dividing burn area into buckets
* Outlier detection methods


## References
In proper APA/MLA format.

1. P. Cortez and A. Morais. A Data Mining Approach to Predict Forest Fires using Meteorological Data. In J. Neves, M. F. Santos and J. Machado Eds., New Trends in Artificial Intelligence, Proceedings of the 13th EPIA 2007 - Portuguese Conference on Artificial Intelligence, December, Guimaraes, Portugal, pp. 512-523, 2007. APPIA, ISBN-13 978-989-95618-0-9. Available at:http://www3.dsi.uminho.pt/pcortez/fires.pdf

2.

