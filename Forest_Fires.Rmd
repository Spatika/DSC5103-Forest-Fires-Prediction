---
title: "DSC5103 Final Project: Forest Fires"
subtitle: 'Prediction of Burn Area using Meteorological Data'
author: "Section A1 Group 10"
date: "Oct 2018"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    number_sections: true
    highlight: tango
    theme: yeti
---
<!--
comments must be put in an HTML comment form
-->

```{r set-options, echo=FALSE, cache=FALSE}
options(width = 100)  # set output width, turn off scientific notation for big numbers
# knitr::opts_chunk$set(echo = TRUE) # include=FALSE
```

# Introduction
We will be studying the Forest Fires Data Set from https://archive.ics.uci.edu/ml/datasets/forest+fires put together and studied by *P. Cortez and A. Morais (2007)*. This dataset covers meteorological and spatio-temporal data for forest fires in Portugal from 2008, with 13 attributes each for 517 data points. Our target attribute from this is 'area', and the meteorological data is that which is registered by sensors at the moment the fire was detected (or first broke out). The 12 other attributes are described and explored in more detail in section 2. 

## Problem 

We will be studying the following problem(s):

* Predict the burned area of a forest fire, given the prevailing meteorological conditions.
    + This data can be obtained in real-time, and is non-costly, and this prediction can provide instant feedback to the appropriate diaster response teams.
    + Could be possibly be imbalanced problem, if converted to multi-class classification.

## Motivation
With forest fires sweeping Southern California, leaving much destruction in their wake, there is need for a tool such as ours to improve firefighting resource management and disaster response. Spin some more stuff on why this work is important, and why we chose it/use case - what Xs you will get in the future to predict this Y.

## Evaluation Metrics
Need to do some work on which one would be appropriate based on problem outlined above.

* Regression - RMSE, MAD
* Classification - recall, overall accuracy, AUC/ROC
* Bingo Classification Accuracy?
* 1-Away Classification Accuracy? 

## Literature Review
While topical, this data set hasn't been studied extensively. However, the frame of reference for our regression task is work by *P. Cortez and A. Morais (2007)*.

Kaggle/GitHub sources:

1. https://www.kaggle.com/elikplim/predict-the-burned-area-of-forest-fires


# Exploratory Data Analysis
We did some initial EDA and visualization to get an idea of our next steps: the required data pre-processing and balancing.

## Schema
```{r eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}
library(tidyverse)
library(psych)
library(caretEnsemble)
library(caret)
library(corrplot)
library(ModelMetrics)

# load data
data <- read.csv(file = "./data/forestfires.csv", stringsAsFactors = T)
summary(data)
```


## Distribution of Target Class
```{r eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}
ggplot(data,aes(data$area)) + geom_histogram()
summary(data$area)
```
We can see that the data is heavily skewed towards small forest fires. There are 247 entries with area = 0, for incidents where the resulting burned area was < 100 m^2. A logarithmic transofrmation of area would be useful in this case, and we can add one to the target column first since ln(0) approaches negative infinity.

## EDA
```{r eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}
# describe(data)

#columns
names(data)
#numeric data
names(Filter(is.numeric,data))
#factor data
names(Filter(is.factor,data))

#check NAs
sum(is.na(data))

# check correlation - there are some colinearity based on which we might drop features
corPlot(Filter(is.numeric,data))

# visualize relation between target and major predictors
pairs(dplyr::select(data,c('rain', 'wind', 'temp', 'RH', 'area', 'DC', 'ISI', 'FFMC')))

# day/month wise incidents
plot(data$day, col='purple')
plot(data$month, col='purple')
# there are more incidents on weekends (fri/sat/sun), it might mean that campers vactioning might have caused/spotted fires


#Day/Month wise area Burnt 
ggplot(data, aes(x=data$month,data$area)) + geom_boxplot(outlier.shape=NA) + 
  geom_jitter(col='red') + theme_bw()

ggplot(data, aes(x=data$day,data$area)) + geom_boxplot(outlier.shape=NA) + 
  geom_jitter(col='red') + theme_bw()
```

# Data Preparation

## Log Transformation
```{r eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}
data$log_area <- log(data$area + 1)

# new distribution
summary(data$log_area)
ggplot(data,aes(data$log_area)) + geom_histogram()
```


## Feature Selection
The 'X' and 'Y' attributes are coordinates in the 9x9 grid representing the area of Portugal's Montesinho Park. Specific to this situation - doesn't make sense to use for a generalized tool, and are anyway not found to be crucial in predicting burned area.
```{r eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}
data0 <- data # old data with all features

data <- dplyr::select(data, -X, -Y)
summary(data)
```

## Normalization
For SVM.
```{r eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}

normalize_c = function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

denormalize <- function(x, min_x, max_x) {
  return(x * (max_x - min_x) + min_x) 
}

# Xs - normalize all predictors (not area or log_area)
data_norm <- data
X <- dplyr::select(data_norm, -log_area, -area) 
data_norm[,1:10] <- X %>% mutate_at(names(Filter(is.numeric, X)), normalize_c)

summary(data_norm)

# remove 'area' from both data_norm and data
area_ha <- data$area # original area
data <- dplyr::select(data, -area)
data_norm <- dplyr::select(data_norm, - area)

```

## Train-Validation Split
Next, we will prepare the training and test dataset.
```{r eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}
# split training and test data 70/30
N <- nrow(data)
set.seed(1)
train.index <- sample(1:N, round(N*0.7))
test.index <- -train.index

```

Separating the data for GBM use:
```{r eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}

library(xgboost)
# convert data for xgboost - onehot encoding is automatically done 
x.train <- model.matrix(log_area ~ ., data=data[train.index, ])[, -11]
y.train <- data[train.index, "log_area"]

dtrain <- xgb.DMatrix(data=x.train, label=y.train)

x.test <- model.matrix(log_area ~ ., data=data[test.index, ])[ ,-11]
y.test <- data[test.index, "log_area"]

```


# Feature Engineering/Creation
```{r eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}

```

# Modelling

## Elastic Net
```{r glmnet, eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}
library(glmnetUtils)
library(MASS)
library(boot)

model_lm = glm(log_area ~ .,
               data=data_norm[train.index,], family = 'gaussian')
summary(model_lm)
glm.diag.plots(model_lm)

# cook's statistics shows that few outliers are heavily affecting prediction
# As shown in the histogram of area, there many values at 0 but few cases with very high area burnt such as 900-1100 ha
# We can't remove these outliers as these are also cases which we are trying to predict

# Residuals plot shows a very flat, instead of a uniform distribution again because of extreme outlier influence

# this means linear regression models will not be good for this case

# inverse log - 1
train_pred_area_lm <- exp(model_lm$fitted.values) - 1
rmse(train_pred_area_lm, area_ha[train.index])

model_step = stepAIC(model_lm, direction = 'both')
model_step$anova

train_pred_area_step = as.numeric(denormalize(model_step$fitted.values,min(data$area), max(data$area)))

sqrt(mean((data[train.index,'area']-train_pred_area_step)^2))

model_lasso = cv.glmnet(area~.,
               data=data_norm[train.index,], nfolds=10, use.model.frame = T, alpha = 1)

lam_lasso = model_lasso$lambda.min

train_pred_area_lasso = as.numeric(denormalize(predict(model_lasso, s=lam_lasso, data_norm[train.index,], exact=TRUE),min(data$area),max(data$area)))

sqrt(mean((data[train.index,'area']-train_pred_area_lasso)^2))

model_ridge = cv.glmnet(area~rain+wind+temp+RH+DC+ISI+FFMC+month+day,
               data=data_norm[train.index,], nfolds=10, use.model.frame = T, alpha = 0)

lam_ridge = model_ridge$lambda.min

train_pred_area_ridge = as.numeric(denormalize(predict(model_ridge, s=lam_ridge, data_norm[train.index,], exact=TRUE),min(data$area),max(data$area)))

sqrt(mean((data[train.index,'area']-train_pred_area_ridge)^2))

# as per initial hypothesis - linear models are found to be unfit for this case. 
```

## k-Nearest Neighbours Regression
```{r}
library(onehot)
library(class)
library(FNN)
library(Metrics)

#encode factors for KNN
data_norm$month = as.factor(data_norm$month)
data_norm$day = as.factor(data_norm$day)

encoder = onehot(data_norm, max_levels = 100)
knn_data = as.data.frame(predict(encoder, data_norm))

#separate train and test for KNN
train_knn = knn_data[train.index,]
test_knn = knn_data[-train.index,]

#Optimal K
ks = 1:30
mse.train = numeric(length=length(ks))
mse.test  = numeric(length=length(ks))

for (i in seq(along=ks)) {
  model.train = knn.reg(train_knn, train_knn, train_knn$area, k=ks[i])
  model.test  = knn.reg(train_knn, test_knn, train_knn$area, k=ks[i])
  mse.train[i] = mean((train_knn$area - model.train$pred)^2)
  mse.test[i] = mean((test_knn$area - model.test$pred)^2)
}

k.opt = ks[which.min(mse.test)]

#training KNN regression

knn_pred = knn.reg(train_knn, test_knn, train_knn$area, k=k.opt)
knn_rmse = rmse(test_knn$area, as.numeric(denormalize(knn_pred$pred,min(data$area), max(data$area))))
knn_rmse # 15.3
```


## Support Vector Machines
```{r}

library(e1071)

train_data = data_norm[train.index,]
test_data = data_norm[-train.index,]

#linear kernel
svm_linear = svm(area ~ rain + wind + temp + RH + DC + ISI + FFMC, data=train_data, kernel = 'linear', cost = 1)
pred.linear = predict(svm_linear, test_data)
pred.linear.denormalized = as.numeric(denormalize(pred.linear,min(data$area), max(data$area)))
svm_lin_rmse = rmse(test_data$area, pred.linear.denormalized)
svm_lin_rmse # 7.4

tune_linear = tune(svm, area ~ rain + wind + temp + RH + DC + ISI + FFMC,  data = train_data, kernel='linear',
                       ranges = list(epsilon = seq(0,1,0.1), cost = 2^(2:6), control = tune.control(sampling = "bootstrap", cross = 5, best.model = TRUE,fix = 2/3,nrepeat = 2)))
tuned_linear = tune_linear$best.model
tuned_linear_pred = predict(tuned_linear, test_data) 
tuned.pred.linear.denormalized = as.numeric(denormalize(tuned_linear_pred,min(data$area), max(data$area)))
svm_lin_tuned_rmse = rmse(test_data$area, tuned.pred.linear.denormalized)
svm_lin_tuned_rmse # 14.8

#polynomial kernel
#svm_poly = svm(area ~ rain + wind + temp + RH + DC + ISI + FFMC, data=train_data, kernel = 'polynomial', cost = 1)
#pred.poly = predict(svm_poly, test_data)
#pred.poly.denormalized = as.numeric(denormalize(pred.poly,min(data$area), max(data$area)))
#svm_poly_rmse = rmse(test_data$area, pred.poly.denormalized)
#svm_poly_rmse # 33.1

#tune_poly = tune(svm, area ~ rain + wind + temp + RH + DC + ISI + FFMC,  data = train_data, kernel='polynomial',
#                   ranges = list(epsilon = seq(0,1,0.1), cost = 2^(2:6), control = tune.control(sampling = "bootstrap", cross = 5, best.model = TRUE,fix = 2/3,nrepeat = 2)))
#tuned_poly = tune_poly$best.model
#uned_poly_pred = predict(tuned_poly, test_data) 
#tuned.pred.poly.denormalized = as.numeric(denormalize(tuned_poly_pred,min(data$area), max(data$area)))
#svm_poly_tuned_rmse = rmse(test_data$area, tuned.pred.poly.denormalized)
#svm_poly_tuned_rmse # 30.8

#RBF kernel
svm_rbf = svm(area ~ rain + wind + temp + RH + DC + ISI + FFMC, data=train_data, kernel = 'radial', cost = 1)
pred.rbf = predict(svm_rbf, test_data)
pred.rbf.denormalized = as.numeric(denormalize(pred.rbf,min(data$area), max(data$area)))
svm_rbf_rmse = rmse(test_data$area, pred.rbf.denormalized)
svm_rbf_rmse # 7.6

tune_rbf = tune(svm, area ~ rain + wind + temp + RH + DC + ISI + FFMC,  data = train_data, kernel='radial',
                 ranges = list(epsilon = seq(0,1,0.1), cost = 2^(2:8), control = tune.control(sampling = "bootstrap", cross = 5, best.model = TRUE,fix = 2/3,nrepeat = 2)))
tuned_rbf = tune_rbf$best.model
tuned_rbf_pred = predict(tuned_rbf, test_data) 
tuned.pred.rbf.denormalized = as.numeric(denormalize(tuned_rbf_pred,min(data$area), max(data$area)))
svm_rbf_tuned_rmse = rmse(test_data$area, tuned.pred.rbf.denormalized)
svm_rbf_tuned_rmse # 17.5

#Sigmoid kernel
#svm_sigmoid = svm(area ~ rain + wind + temp + RH + DC + ISI + FFMC, data=train_data, kernel = 'sigmoid', cost = 1)
#pred.sigmoid = predict(svm_sigmoid, test_data)
#pred.sigmoid.denormalized = as.numeric(denormalize(pred.sigmoid,min(data$area), max(data$area)))
#svm_sigmoid_rmse = rmse(test_data$area, pred.sigmoid.denormalized)
#svm_sigmoid_rmse 

#tune_sigmoid = tune(svm, area ~ rain + wind + temp + RH + DC + ISI + FFMC,  data = train_data, kernel='sigmoid',
#                ranges = list(epsilon = seq(0,1,0.1), cost = 2^(2:8), control = tune.control(sampling = "bootstrap", cross = 5, best.model = TRUE,fix = 2/3,nrepeat = 2)))
#tuned_sigmoid = tune_sigmoid$best.model
#tuned_sigmoid_pred = predict(tuned_sigmoid, test_data) 
#tuned.pred.sigmoid.denormalized = as.numeric(denormalize(tuned_sigmoid_pred,min(data$area), max(data$area)))
#svm_sigmoid_tuned_rmse = rmse(test_data$area, tuned.pred.sigmoid.denormalized)
#svm_sigmoid_tuned_rmse 

```


## Random Forest
```{r randomforest, eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}
library("randomForest")

# tune random forest (mtry) manually
mse.rfs <- rep(0, 10) # repeat '0' 10 times

for(m in 1:10){
    set.seed(12345)
    rf <- randomForest(log_area ~ ., data = data, subset = train.index, ntree=501, mtry=m)
    mse.rfs[m] <- rf$mse[501]
}

plot(1:10, mse.rfs, type = "b", xlab="mtry", ylab="OOB Error")

# fit a random forest model
set.seed(12345)
model.rf <- randomForest(log_area ~ ., data = data, subset=train.index, ntree=501, mtry=1)
plot(model.rf)

# predict
pred.rf <- predict(model.rf, newdata=data[test.index,]) 

# inverse log - 1
pred.rf <- exp(pred.rf) - 1

# rmse in test data
rmse(pred.rf, area_ha[test.index]) # ~27.80
```

## XGBoost
```{r xgboost, eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}

# fit a boosting model with optimal parameters - from running 9-xgboost_tuning.R with dtrain as input
max_depth.opt <- 2
eta.opt <- 0.005
subsample.opt <- 1
colsample.opt <- 1
nrounds.opt <- 134

set.seed(12345)
model.xgb <- xgboost(data=dtrain, objective="reg:linear", nrounds=nrounds.opt, max_depth = max_depth.opt, eta=eta.opt, subsample=subsample.opt, colsample_bytree=colsample.opt , verbose=0)

# predict
pred.xgb <- predict(model.xgb, x.test)

# inverse log
pred.xgb <- exp(pred.xgb) - 1

# rmse
rmse(pred.xgb, area_ha[test.index]) # ~28.02
```

### XGBoost Variable Importance Plot
```{r xgb varimp, eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE}

importance_matrix <- xgb.importance(model = model.xgb, feature_names = colnames(x.train))
importance_matrix
xgb.plot.importance(importance_matrix=importance_matrix)

```

## Ensemble 
```{r ensemble, eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE, warning=FALSE}

area_corr <- cor(dplyr::select(data, -c("month", "day")))
corrplot(area_corr, method = "circle")

set.seed(17)

train.index <- createDataPartition(data$area, p = .8, list = FALSE)
ensemble_train <- data[train.index,]
ensemble_test <- data[-train.index,]

folds <- createFolds(ensemble_train$area,5)

control <- trainControl(method='repeatedcv', number=5, repeats=2, index=folds, search = 'grid', savePredictions = 'final')

algos <- c('svmLinear','knn')

models <- caretList(area~., data=ensemble_train, metric = 'RMSE', trControl=control, methodList=algos)

models_perf <- resamples(models)
modelCor(models_perf)

stack_control <- trainControl(method = 'repeatedcv', number = 2, repeats = 5)

stack_lm <- caretStack(models, method='lm',  trControl=stack_control)

pred_stack <- predict(stack_lm, ensemble_test)

## Accuracy and RMSE of Stacking Model
stack_accuracy <- RMSE(pred_stack, ensemble_test$area)
stack_accuracy # 13.68


```

# Results and Model Comparison
* We select RMSE as our performance metric and observe that both KNN and SVM Linear gives us pretty good results as compared to the other models.Hence, we stack the above two models to augment our results. We find that the combination of these also gives a similar positive result.
* We notice that not all variables are significant in predicting the area(Dependent Variable) from the correlation plot. Hence we drop all the index and RH and use temp instead which is highly correlated to all. We also drop the X and Y coordinates as these do not seem to affect the area.

```{r ensemble_varimp, eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE, warning=FALSE}

## Stacking Model with VarImp

set.seed(17)

models_varimp <- caretList(area ~ temp + wind + rain, data=ensemble_train, metric = 'RMSE', trControl=control, methodList=algos)

models_perf_varimp <- resamples(models)
modelCor(models_perf_varimp)

stack_lm_varimp <- caretStack(models_varimp, method='lm',  trControl=stack_control)

pred_stack_varimp <- predict(stack_lm_varimp, ensemble_test)

## Accuracy and RMSE of Stacking Model
stack_accuracy <- RMSE(pred_stack_varimp, ensemble_test$area)
stack_accuracy # 14.41


```


# Insights
* The final model using significant variables contains a similar RMSE as compared to using all independent variables. Hence, we can say that the area is indeed dependent on temperature, wind and rain. The other variables do not contribute in predicting the area. 
* The best and similar results obtained are by using SVM, KNN or a combination of both.


# Multi-Class Classification

## Data Preparation
```{r multiclass prep, eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE, warning=FALSE}



```

## Modelling
```{r multiclass model, eval=TRUE, echo=TRUE, message=FALSE, tidy=TRUE, warning=FALSE}



```

## Discussion


# Conclusion
* It is difficult to predict the exact area which would be affected by a forest fire since our data consists of a huge range of area, and small fires tend to be more frequent.
* We could probably segment the area into different classes of the Severity of Damage (Low, Medium, High and Fatal) and consider it as multi-class problem.

# References

1. Cortez, P., & Morais, A. D. J. R. (2007). A data mining approach to predict forest fires using meteorological data. Available at: http://www3.dsi.uminho.pt/pcortez/fires.pdf

2. Özbayoğlu, A. M., & Bozer, R. (2012). Estimation of the burned area in forest fires using computational intelligence techniques. Procedia Computer Science, 12, 282-287.

